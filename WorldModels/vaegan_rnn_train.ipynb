{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e818139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "\n",
    "from vaegan_rnn import MDNRNN, sample_vae\n",
    "from utils import PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e81f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "np.set_printoptions(precision=4, edgeitems=6, linewidth=100, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3a41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"results/WorldModels/CarRacing-v0/vaegan_series\"\n",
    "model_save_path = \"results/WorldModels/CarRacing-v0/vaegan_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a50573",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_path):\n",
    "  os.makedirs(model_save_path)\n",
    "#with open(model_save_path + '/args.json', 'w') as f:\n",
    "#    json.dump(args.__dict__, f, indent=2)\n",
    "raw_data = np.load(os.path.join(DATA_DIR, \"series.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c289eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mu = raw_data[\"mu\"]\n",
    "data_logvar = raw_data[\"logvar\"]\n",
    "data_action =  raw_data[\"action\"]\n",
    "data_r = raw_data[\"reward\"]\n",
    "data_d = raw_data[\"done\"]\n",
    "data_N = raw_data[\"N\"]\n",
    "N_data = len(data_mu) # should be 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa55e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    }
   ],
   "source": [
    "print(N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93ab5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_gen():\n",
    "  for _ in range(4000):\n",
    "    indices = np.random.permutation(N_data)[0:5]\n",
    "    # suboptimal b/c we are always only taking first set of steps\n",
    "    mu = data_mu[indices][:, :1000] \n",
    "    logvar = data_logvar[indices][:, :1000]\n",
    "    action = data_action[indices][:, :1000]\n",
    "    z = sample_vae(mu, logvar)\n",
    "    r = tf.cast(data_r[indices], tf.float16)[:, :1000]\n",
    "    d = tf.cast(data_d[indices], tf.float16)[:, :1000]\n",
    "    N = tf.cast(data_N[indices], tf.float16)[:, :1000]\n",
    "    yield z, action, r, d, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9aa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(ds_gen, output_types=(tf.float16, tf.float16, tf.float16, tf.float16, tf.float16), \\\n",
    "    output_shapes=((5, 1000, 512), \\\n",
    "    (5, 1000, 3), \\\n",
    "    (5, 1000, 1), \\\n",
    "    (5, 1000, 1), \\\n",
    "    (5, 1000, 1)))\n",
    "dataset = dataset.prefetch(10)\n",
    "tensorboard_dir = os.path.join(model_save_path, 'tensorboard')\n",
    "summary_writer = tf.summary.create_file_writer(tensorboard_dir)\n",
    "summary_writer.set_as_default()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_dir, write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49b4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = MDNRNN()\n",
    "rnn.compile(optimizer=rnn.optimizer, loss=rnn.get_loss())\n",
    "tensorboard_callback.set_model(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f9a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/distributions/distribution.py:332: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "WARNING:tensorflow:Layer lstm is casting an input tensor from dtype float16 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float16 by default, call `tf.keras.backend.set_floatx('float16')`. To change just this layer, pass dtype='float16' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "step: 20, train_time_taken: 7.6290, lr: 0.001000, loss: 1.1854\n",
      "step: 40, train_time_taken: 2.1516, lr: 0.001000, loss: 1.0582\n",
      "step: 60, train_time_taken: 2.1479, lr: 0.001000, loss: 0.9677\n",
      "step: 80, train_time_taken: 2.1566, lr: 0.001000, loss: 0.9312\n",
      "step: 100, train_time_taken: 2.1469, lr: 0.001000, loss: 0.9794\n",
      "step: 120, train_time_taken: 2.1395, lr: 0.001000, loss: 0.9602\n",
      "step: 140, train_time_taken: 2.1512, lr: 0.001000, loss: 0.8953\n",
      "step: 160, train_time_taken: 2.1357, lr: 0.001000, loss: 0.9152\n",
      "step: 180, train_time_taken: 2.1591, lr: 0.001000, loss: 0.8751\n",
      "step: 200, train_time_taken: 2.1578, lr: 0.001000, loss: 0.9031\n",
      "step: 220, train_time_taken: 2.1595, lr: 0.001000, loss: 0.8331\n",
      "step: 240, train_time_taken: 2.1519, lr: 0.001000, loss: 0.8904\n",
      "step: 260, train_time_taken: 2.1606, lr: 0.001000, loss: 0.9103\n",
      "step: 280, train_time_taken: 2.1566, lr: 0.001000, loss: 0.7940\n",
      "step: 300, train_time_taken: 2.1503, lr: 0.001000, loss: 0.8347\n",
      "step: 320, train_time_taken: 2.1471, lr: 0.001000, loss: 0.8867\n",
      "step: 340, train_time_taken: 2.1515, lr: 0.001000, loss: 0.8711\n",
      "step: 360, train_time_taken: 2.1603, lr: 0.001000, loss: 0.8390\n",
      "step: 380, train_time_taken: 2.1488, lr: 0.001000, loss: 0.8962\n",
      "step: 400, train_time_taken: 2.1550, lr: 0.001000, loss: 0.7707\n",
      "step: 420, train_time_taken: 2.1531, lr: 0.001000, loss: 0.8621\n",
      "step: 440, train_time_taken: 2.1677, lr: 0.001000, loss: 0.8789\n",
      "step: 460, train_time_taken: 2.1573, lr: 0.001000, loss: 0.8310\n",
      "step: 480, train_time_taken: 2.1731, lr: 0.001000, loss: 0.7936\n",
      "step: 500, train_time_taken: 2.1604, lr: 0.001000, loss: 0.8334\n",
      "step: 520, train_time_taken: 2.1576, lr: 0.001000, loss: 0.9039\n",
      "step: 540, train_time_taken: 2.1518, lr: 0.001000, loss: 0.8350\n",
      "step: 560, train_time_taken: 2.1844, lr: 0.001000, loss: 0.7813\n",
      "step: 580, train_time_taken: 2.1637, lr: 0.001000, loss: 0.8434\n",
      "step: 600, train_time_taken: 2.1797, lr: 0.001000, loss: 0.8514\n",
      "step: 620, train_time_taken: 2.1725, lr: 0.001000, loss: 0.7927\n",
      "step: 640, train_time_taken: 2.1635, lr: 0.001000, loss: 0.8394\n",
      "step: 660, train_time_taken: 2.1863, lr: 0.001000, loss: 0.8326\n",
      "step: 680, train_time_taken: 2.1701, lr: 0.001000, loss: 0.8682\n",
      "step: 700, train_time_taken: 2.1736, lr: 0.001000, loss: 0.8560\n",
      "step: 720, train_time_taken: 2.1692, lr: 0.001000, loss: 0.8323\n",
      "step: 740, train_time_taken: 2.1859, lr: 0.001000, loss: 0.8167\n",
      "step: 760, train_time_taken: 2.1796, lr: 0.001000, loss: 0.7882\n",
      "step: 780, train_time_taken: 2.1819, lr: 0.001000, loss: 0.8333\n",
      "step: 800, train_time_taken: 2.2051, lr: 0.001000, loss: 0.8057\n",
      "step: 820, train_time_taken: 2.1852, lr: 0.001000, loss: 0.8162\n",
      "step: 840, train_time_taken: 2.1912, lr: 0.001000, loss: 0.8416\n",
      "step: 860, train_time_taken: 2.1895, lr: 0.001000, loss: 0.8544\n",
      "step: 880, train_time_taken: 2.2105, lr: 0.001000, loss: 0.7866\n",
      "step: 900, train_time_taken: 2.1724, lr: 0.001000, loss: 0.8846\n",
      "step: 920, train_time_taken: 2.1899, lr: 0.001000, loss: 0.8197\n",
      "step: 940, train_time_taken: 2.1997, lr: 0.001000, loss: 0.8107\n",
      "step: 960, train_time_taken: 2.1640, lr: 0.001000, loss: 0.8457\n",
      "step: 980, train_time_taken: 2.2097, lr: 0.001000, loss: 0.8182\n",
      "step: 1000, train_time_taken: 2.2068, lr: 0.001000, loss: 0.8537\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: results/WorldModels/CarRacing-v0/vaegan_rnn/assets\n",
      "step: 1020, train_time_taken: 5.8093, lr: 0.001000, loss: 0.7618\n",
      "step: 1040, train_time_taken: 2.1765, lr: 0.001000, loss: 0.8635\n",
      "step: 1060, train_time_taken: 2.1705, lr: 0.001000, loss: 0.8777\n",
      "step: 1080, train_time_taken: 2.1690, lr: 0.001000, loss: 0.7933\n",
      "step: 1100, train_time_taken: 2.1819, lr: 0.001000, loss: 0.7894\n",
      "step: 1120, train_time_taken: 2.1691, lr: 0.001000, loss: 0.8078\n",
      "step: 1140, train_time_taken: 2.1611, lr: 0.001000, loss: 0.8075\n",
      "step: 1160, train_time_taken: 2.1758, lr: 0.001000, loss: 0.7966\n",
      "step: 1180, train_time_taken: 2.1575, lr: 0.001000, loss: 0.7488\n",
      "step: 1200, train_time_taken: 2.1508, lr: 0.001000, loss: 0.7982\n",
      "step: 1220, train_time_taken: 2.1667, lr: 0.001000, loss: 0.8355\n",
      "step: 1240, train_time_taken: 2.1608, lr: 0.001000, loss: 0.8164\n",
      "step: 1260, train_time_taken: 2.1665, lr: 0.001000, loss: 0.7996\n",
      "step: 1280, train_time_taken: 2.1675, lr: 0.001000, loss: 0.8363\n",
      "step: 1300, train_time_taken: 2.1615, lr: 0.001000, loss: 0.8283\n",
      "step: 1320, train_time_taken: 2.1617, lr: 0.001000, loss: 0.7904\n",
      "step: 1340, train_time_taken: 2.1615, lr: 0.001000, loss: 0.7813\n",
      "step: 1360, train_time_taken: 2.1635, lr: 0.001000, loss: 0.8082\n",
      "step: 1380, train_time_taken: 2.1558, lr: 0.001000, loss: 0.8575\n",
      "step: 1400, train_time_taken: 2.1482, lr: 0.001000, loss: 0.7793\n",
      "step: 1420, train_time_taken: 2.1701, lr: 0.001000, loss: 0.8640\n",
      "step: 1440, train_time_taken: 2.1594, lr: 0.001000, loss: 0.7924\n",
      "step: 1460, train_time_taken: 2.1553, lr: 0.001000, loss: 0.8388\n",
      "step: 1480, train_time_taken: 2.1608, lr: 0.001000, loss: 0.8473\n",
      "step: 1500, train_time_taken: 2.1578, lr: 0.001000, loss: 0.8280\n",
      "step: 1520, train_time_taken: 2.1608, lr: 0.001000, loss: 0.8004\n",
      "step: 1540, train_time_taken: 2.1592, lr: 0.001000, loss: 0.7923\n",
      "step: 1560, train_time_taken: 2.1504, lr: 0.001000, loss: 0.8226\n",
      "step: 1580, train_time_taken: 2.1628, lr: 0.001000, loss: 0.8428\n",
      "step: 1600, train_time_taken: 2.1545, lr: 0.001000, loss: 0.7558\n",
      "step: 1620, train_time_taken: 2.1600, lr: 0.001000, loss: 0.7389\n",
      "step: 1640, train_time_taken: 2.1492, lr: 0.001000, loss: 0.7103\n",
      "step: 1660, train_time_taken: 2.1545, lr: 0.001000, loss: 0.7510\n",
      "step: 1680, train_time_taken: 2.1545, lr: 0.001000, loss: 0.8220\n",
      "step: 1700, train_time_taken: 2.1505, lr: 0.001000, loss: 0.8212\n",
      "step: 1720, train_time_taken: 2.1590, lr: 0.001000, loss: 0.8393\n",
      "step: 1740, train_time_taken: 2.1761, lr: 0.001000, loss: 0.7865\n",
      "step: 1760, train_time_taken: 2.1423, lr: 0.001000, loss: 0.7257\n",
      "step: 1780, train_time_taken: 2.1575, lr: 0.001000, loss: 0.8298\n",
      "step: 1800, train_time_taken: 2.1615, lr: 0.001000, loss: 0.8088\n",
      "step: 1820, train_time_taken: 2.1604, lr: 0.001000, loss: 0.7567\n",
      "step: 1840, train_time_taken: 2.1548, lr: 0.001000, loss: 0.7201\n",
      "step: 1860, train_time_taken: 2.1623, lr: 0.001000, loss: 0.8490\n",
      "step: 1880, train_time_taken: 2.1679, lr: 0.001000, loss: 0.7977\n",
      "step: 1900, train_time_taken: 2.1774, lr: 0.001000, loss: 0.7495\n",
      "step: 1920, train_time_taken: 2.1706, lr: 0.001000, loss: 0.7584\n",
      "step: 1940, train_time_taken: 2.1663, lr: 0.001000, loss: 0.7774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1960, train_time_taken: 2.1597, lr: 0.001000, loss: 0.7476\n",
      "step: 1980, train_time_taken: 2.1624, lr: 0.001000, loss: 0.7546\n",
      "step: 2000, train_time_taken: 2.1552, lr: 0.001000, loss: 0.7834\n",
      "INFO:tensorflow:Assets written to: results/WorldModels/CarRacing-v0/vaegan_rnn/assets\n",
      "step: 2020, train_time_taken: 5.7942, lr: 0.001000, loss: 0.8443\n",
      "step: 2040, train_time_taken: 2.1621, lr: 0.001000, loss: 0.7424\n",
      "step: 2060, train_time_taken: 2.1543, lr: 0.001000, loss: 0.8144\n",
      "step: 2080, train_time_taken: 2.1712, lr: 0.001000, loss: 0.7553\n",
      "step: 2100, train_time_taken: 2.1556, lr: 0.001000, loss: 0.8312\n",
      "step: 2120, train_time_taken: 2.1446, lr: 0.001000, loss: 0.7023\n",
      "step: 2140, train_time_taken: 2.1560, lr: 0.001000, loss: 0.7177\n",
      "step: 2160, train_time_taken: 2.1521, lr: 0.001000, loss: 0.7916\n",
      "step: 2180, train_time_taken: 2.1615, lr: 0.001000, loss: 0.7594\n",
      "step: 2200, train_time_taken: 2.1583, lr: 0.001000, loss: 0.7426\n",
      "step: 2220, train_time_taken: 2.1523, lr: 0.001000, loss: 0.7855\n",
      "step: 2240, train_time_taken: 2.1587, lr: 0.001000, loss: 0.7878\n",
      "step: 2260, train_time_taken: 2.1604, lr: 0.001000, loss: 0.8493\n",
      "step: 2280, train_time_taken: 2.1717, lr: 0.001000, loss: 0.7383\n",
      "step: 2300, train_time_taken: 2.1708, lr: 0.001000, loss: 0.8366\n",
      "step: 2320, train_time_taken: 2.1624, lr: 0.001000, loss: 0.7619\n",
      "step: 2340, train_time_taken: 2.1746, lr: 0.001000, loss: 0.7573\n",
      "step: 2360, train_time_taken: 2.1638, lr: 0.001000, loss: 0.7144\n",
      "step: 2380, train_time_taken: 2.1642, lr: 0.001000, loss: 0.7897\n",
      "step: 2400, train_time_taken: 2.1580, lr: 0.001000, loss: 0.7412\n",
      "step: 2420, train_time_taken: 2.1653, lr: 0.001000, loss: 0.8023\n",
      "step: 2440, train_time_taken: 2.1730, lr: 0.001000, loss: 0.7970\n",
      "step: 2460, train_time_taken: 2.1574, lr: 0.001000, loss: 0.7976\n",
      "step: 2480, train_time_taken: 2.1651, lr: 0.001000, loss: 0.8113\n",
      "step: 2500, train_time_taken: 2.1678, lr: 0.001000, loss: 0.7155\n",
      "step: 2520, train_time_taken: 2.1620, lr: 0.001000, loss: 0.7067\n",
      "step: 2540, train_time_taken: 2.1830, lr: 0.001000, loss: 0.8060\n",
      "step: 2560, train_time_taken: 2.1666, lr: 0.001000, loss: 0.7566\n",
      "step: 2580, train_time_taken: 2.1641, lr: 0.001000, loss: 0.8032\n",
      "step: 2600, train_time_taken: 2.1828, lr: 0.001000, loss: 0.8040\n",
      "step: 2620, train_time_taken: 2.1804, lr: 0.001000, loss: 0.8238\n",
      "step: 2640, train_time_taken: 2.1816, lr: 0.001000, loss: 0.8551\n",
      "step: 2660, train_time_taken: 2.1693, lr: 0.001000, loss: 0.7249\n",
      "step: 2680, train_time_taken: 2.1756, lr: 0.001000, loss: 0.8048\n",
      "step: 2700, train_time_taken: 2.1750, lr: 0.001000, loss: 0.7507\n",
      "step: 2720, train_time_taken: 2.1690, lr: 0.001000, loss: 0.7808\n",
      "step: 2740, train_time_taken: 2.1667, lr: 0.001000, loss: 0.7797\n",
      "step: 2760, train_time_taken: 2.1829, lr: 0.001000, loss: 0.8194\n",
      "step: 2780, train_time_taken: 2.1774, lr: 0.001000, loss: 0.8256\n",
      "step: 2800, train_time_taken: 2.1668, lr: 0.001000, loss: 0.8306\n",
      "step: 2820, train_time_taken: 2.1728, lr: 0.001000, loss: 0.7849\n",
      "step: 2840, train_time_taken: 2.1800, lr: 0.001000, loss: 0.8266\n",
      "step: 2860, train_time_taken: 2.1779, lr: 0.001000, loss: 0.8521\n",
      "step: 2880, train_time_taken: 2.1842, lr: 0.001000, loss: 0.7670\n",
      "step: 2900, train_time_taken: 2.1737, lr: 0.001000, loss: 0.7057\n",
      "step: 2920, train_time_taken: 2.1772, lr: 0.001000, loss: 0.8033\n",
      "step: 2940, train_time_taken: 2.1870, lr: 0.001000, loss: 0.8328\n",
      "step: 2960, train_time_taken: 2.1770, lr: 0.001000, loss: 0.8569\n",
      "step: 2980, train_time_taken: 2.1727, lr: 0.001000, loss: 0.7636\n",
      "step: 3000, train_time_taken: 2.1721, lr: 0.001000, loss: 0.7758\n",
      "INFO:tensorflow:Assets written to: results/WorldModels/CarRacing-v0/vaegan_rnn/assets\n",
      "step: 3020, train_time_taken: 5.7788, lr: 0.001000, loss: 0.8543\n",
      "step: 3040, train_time_taken: 2.1787, lr: 0.001000, loss: 0.8068\n",
      "step: 3060, train_time_taken: 2.1904, lr: 0.001000, loss: 0.7969\n",
      "step: 3080, train_time_taken: 2.1774, lr: 0.001000, loss: 0.8780\n",
      "step: 3100, train_time_taken: 2.1873, lr: 0.001000, loss: 0.7707\n",
      "step: 3120, train_time_taken: 2.1963, lr: 0.001000, loss: 0.8274\n",
      "step: 3140, train_time_taken: 2.1675, lr: 0.001000, loss: 0.7842\n",
      "step: 3160, train_time_taken: 2.1966, lr: 0.001000, loss: 0.7441\n",
      "step: 3180, train_time_taken: 2.1847, lr: 0.001000, loss: 0.7816\n",
      "step: 3200, train_time_taken: 2.1780, lr: 0.001000, loss: 0.8041\n",
      "step: 3220, train_time_taken: 2.1816, lr: 0.001000, loss: 0.8200\n",
      "step: 3240, train_time_taken: 2.1922, lr: 0.001000, loss: 0.8135\n",
      "step: 3260, train_time_taken: 2.1922, lr: 0.001000, loss: 0.7841\n",
      "step: 3280, train_time_taken: 2.1784, lr: 0.001000, loss: 0.7671\n",
      "step: 3300, train_time_taken: 2.1928, lr: 0.001000, loss: 0.7064\n",
      "step: 3320, train_time_taken: 2.1776, lr: 0.001000, loss: 0.7686\n",
      "step: 3340, train_time_taken: 2.2048, lr: 0.001000, loss: 0.7592\n",
      "step: 3360, train_time_taken: 2.1865, lr: 0.001000, loss: 0.8090\n",
      "step: 3380, train_time_taken: 2.1811, lr: 0.001000, loss: 0.7095\n",
      "step: 3400, train_time_taken: 2.2182, lr: 0.001000, loss: 0.8060\n",
      "step: 3420, train_time_taken: 2.2129, lr: 0.001000, loss: 0.7709\n",
      "step: 3440, train_time_taken: 2.1954, lr: 0.001000, loss: 0.7371\n",
      "step: 3460, train_time_taken: 2.1988, lr: 0.001000, loss: 0.7483\n",
      "step: 3480, train_time_taken: 2.2095, lr: 0.001000, loss: 0.8576\n",
      "step: 3500, train_time_taken: 2.1997, lr: 0.001000, loss: 0.7287\n",
      "step: 3520, train_time_taken: 2.2152, lr: 0.001000, loss: 0.7923\n",
      "step: 3540, train_time_taken: 2.2118, lr: 0.001000, loss: 0.8116\n",
      "step: 3560, train_time_taken: 2.2128, lr: 0.001000, loss: 0.7743\n",
      "step: 3580, train_time_taken: 2.2137, lr: 0.001000, loss: 0.7945\n",
      "step: 3600, train_time_taken: 2.2060, lr: 0.001000, loss: 0.7362\n",
      "step: 3620, train_time_taken: 2.2004, lr: 0.001000, loss: 0.7805\n",
      "step: 3640, train_time_taken: 2.2094, lr: 0.001000, loss: 0.8213\n",
      "step: 3660, train_time_taken: 2.2242, lr: 0.001000, loss: 0.7448\n",
      "step: 3680, train_time_taken: 2.1987, lr: 0.001000, loss: 0.7783\n",
      "step: 3700, train_time_taken: 2.2024, lr: 0.001000, loss: 0.7946\n",
      "step: 3720, train_time_taken: 2.1888, lr: 0.001000, loss: 0.7967\n",
      "step: 3740, train_time_taken: 2.2096, lr: 0.001000, loss: 0.7995\n",
      "step: 3760, train_time_taken: 2.1781, lr: 0.001000, loss: 0.7968\n",
      "step: 3780, train_time_taken: 2.2084, lr: 0.001000, loss: 0.7760\n",
      "step: 3800, train_time_taken: 2.2073, lr: 0.001000, loss: 0.7566\n",
      "step: 3820, train_time_taken: 2.1733, lr: 0.001000, loss: 0.7871\n",
      "step: 3840, train_time_taken: 2.1866, lr: 0.001000, loss: 0.7490\n",
      "step: 3860, train_time_taken: 2.1859, lr: 0.001000, loss: 0.7864\n",
      "step: 3880, train_time_taken: 2.1790, lr: 0.001000, loss: 0.7647\n",
      "step: 3900, train_time_taken: 2.1807, lr: 0.001000, loss: 0.7896\n",
      "step: 3920, train_time_taken: 2.1675, lr: 0.001000, loss: 0.7506\n",
      "step: 3940, train_time_taken: 2.1650, lr: 0.001000, loss: 0.7750\n",
      "step: 3960, train_time_taken: 2.1611, lr: 0.001000, loss: 0.7336\n",
      "step: 3980, train_time_taken: 2.1665, lr: 0.001000, loss: 0.8113\n"
     ]
    }
   ],
   "source": [
    "# train loop:\n",
    "start = time.time()\n",
    "step = 0\n",
    "for raw_z, raw_a, raw_r, raw_d, raw_N in dataset:\n",
    "    curr_learning_rate = (0.001-0.00001) * (1.0) ** step + 0.00001\n",
    "    rnn.optimizer.learning_rate = curr_learning_rate\n",
    "    \n",
    "    inputs = tf.concat([raw_z, raw_a], axis=2)\n",
    "\n",
    "    if step == 0:\n",
    "        rnn._set_inputs(inputs)\n",
    "\n",
    "    dummy_zero = tf.zeros([raw_z.shape[0], 1, raw_z.shape[2]], dtype=tf.float16)\n",
    "    z_targ = tf.concat([raw_z[:, 1:, :], dummy_zero], axis=1) # zero pad the end but we don't actually use it\n",
    "    z_mask = 1.0 - raw_d\n",
    "    z_targ = tf.concat([z_targ, z_mask], axis=2) # use a signal to not pass grad\n",
    "\n",
    "    outputs = {'MDN': z_targ}\n",
    "    '''\n",
    "    if args.rnn_r_pred == 1:\n",
    "        r_mask = tf.concat([tf.ones([5, 1, 1], dtype=tf.float16), 1.0 - raw_d[:, :-1, :]], axis=1)\n",
    "        r_targ = tf.concat([raw_r, r_mask], axis=2)\n",
    "        outputs['r'] = r_targ\n",
    "    if args.rnn_d_pred == 1:\n",
    "        d_mask = tf.concat([tf.ones([5, 1, 1], dtype=tf.float16), 1.0 - raw_d[:, :-1, :]], axis=1)\n",
    "        d_targ = tf.concat([raw_d, d_mask], axis=2)\n",
    "        outputs['d'] = d_targ\n",
    "    '''\n",
    "    loss = rnn.train_on_batch(x=inputs, y=outputs, return_dict=True)\n",
    "    [tf.summary.scalar(loss_key, loss_val, step=step) for loss_key, loss_val in loss.items()]\n",
    "\n",
    "    if (step%20==0 and step > 0):\n",
    "        end = time.time()\n",
    "        time_taken = end-start\n",
    "        start = time.time()\n",
    "        output_log = \"step: %d, train_time_taken: %.4f, lr: %.6f\" % (step, time_taken, curr_learning_rate)\n",
    "        for loss_key, loss_val in loss.items():\n",
    "            output_log += ', {}: {:.4f}'.format(loss_key, loss_val)\n",
    "        print(output_log)\n",
    "    if (step%1000==0 and step > 0):\n",
    "        tf.keras.models.save_model(rnn, model_save_path, include_optimizer=True, save_format='tf')\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857885c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
